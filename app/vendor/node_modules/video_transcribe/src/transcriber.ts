import { v1p1beta1 } from '@google-cloud/speech';
import { google } from '@google-cloud/speech/build/protos/protos';

const spawn = require('child_process').spawn;
import * as ffmpeg from 'ffmpeg-static';
import { Utils } from './utils';
import * as fs from 'fs';

import rimraf from 'rimraf';

import { Storage } from '@google-cloud/storage';
import { SubtitleSegment } from './models/transcription_segment';

export class Transcriber {

    language: string;
    client: v1p1beta1.SpeechClient;
    enableAutomaticPunctuation: boolean = false;
    storage: Storage;

    constructor(credentialsPath: string, language: string, enableAutomaticPunctuation: boolean) {
        this.client = new v1p1beta1.SpeechClient({
            keyFilename: credentialsPath
        });
        this.storage = new Storage({
            projectId: 'talkingpnts',
            keyFilename: credentialsPath
        });
        this.enableAutomaticPunctuation = enableAutomaticPunctuation;
        this.language = language;
    }

    async _getAudioFromUrl(sourceFileurl: string, jobId: String): Promise<string> {
        return new Promise((resolve, reject) => {
            console.log("Downloading file: " + sourceFileurl);
            const filePath = `${Utils.tempPath}/${jobId}.video`;
            const file = fs.createWriteStream(filePath);

            const request = require('request').defaults({ encoding: null });
            request.get(sourceFileurl, (error, response, body) => {
                if (!error && response.statusCode == 200) {
                    const buff = Buffer.from(body);//.toString('base64');
                    file.write(buff);
                    resolve(filePath);
                }
            });
        });
    };

    _convertAudio(sourceFilePath: string, jobId: String): Promise<string> {
        return new Promise((resolve, reject) => {
            console.log('sourceFilePath:', sourceFilePath);

            const outputDestination = `${Utils.tempPath}/${jobId}.wav`;

            const args = ['-i', sourceFilePath, '-ac', '1', '-ab', '6400', '-ar', '8000', outputDestination, '-y']

            const process = spawn(ffmpeg.default, args);

            process.stdout.on('data', (data: string) => {
                if (process.env.VERBOSE_FFMPEG) {
                    console.log(`stdout: ${data}`);
                }
            });

            process.stderr.on('data', (data: string) => {
                //console.error(`stderr: ${data}`);
            });

            process.on('close', (code: number) => {
                if (code == 1) {
                    console.log(`FFMPEG exited with status code 1 while converting ${sourceFilePath}`);
                    reject();
                } else if (code == 0) {
                    //console.log('FFMPEG finished');
                    resolve(outputDestination);
                }
            });

        });
    };

    async _uploadToGoogleCloudStorage(wavPath: string, jobId: string) {
        return new Promise<string>(async (resolve, reject) => {

            const bucket = this.storage.bucket("video_captions");
            await bucket.upload(wavPath, {});

            console.log(`${wavPath} uploaded to video_captions.`);
            console.log();

            resolve(`gs://video_captions/${jobId}.wav`);
        });
    }

    _removeFromGoogleCloudStorage(jobId: string) {
        const bucket = this.storage.bucket("video_captions");
        bucket.file(`${jobId}.wav`).delete();
    }


    async generateSubs(audioUrl: string, jobId: string): Promise<SubtitleSegment[]> {

        const video = await this._getAudioFromUrl(audioUrl, jobId);
        const wav = await this._convertAudio(video, jobId);

        const gs = await this._uploadToGoogleCloudStorage(wav, jobId);

        const config: google.cloud.speech.v1p1beta1.IRecognitionConfig = {
            encoding: 'LINEAR16',
            languageCode: this.language,
            model: 'video',
            useEnhanced: true,
            enableAutomaticPunctuation: this.enableAutomaticPunctuation,
            maxAlternatives: 1,
            enableSpeakerDiarization: true,
            enableWordTimeOffsets: true,
        };


        const audio = {
            uri: gs
        };

        const request: google.cloud.speech.v1p1beta1.IRecognizeRequest = {
            config: config,
            audio: audio,
        };

        const [operation] = await this.client.longRunningRecognize(request);

        const [response] = await operation.promise();

        let words = [];

        for (let r of response.results) {
            const a = r.alternatives[0];
            if (!!a.transcript) {
                words = [...words, ...a.words];
            }
        }

        const subtitiles: SubtitleSegment[] = [];
        let currentWords = [];

        for (const [i, word] of words.entries()) {
            const start = parseFloat(word.startTime.seconds) + word.startTime.nanos / 1000000000;
            const end = parseFloat(word.endTime.seconds) + word.endTime.nanos / 1000000000;
            let text = word.word;

            let timeDiff = 0;
            if (i + 1 < words.length) {
                const nextWordStart = parseFloat(words[i + 1].startTime.seconds) + words[i + 1].startTime.nanos / 1000000000;
                timeDiff = nextWordStart - end;
            }

            currentWords.push({ start, end, text });

            if (text.endsWith(".") || text.endsWith("?") || timeDiff > 0.1) {
                subtitiles.push(new SubtitleSegment(currentWords[0].start, end, currentWords.map(w => w.text).join(" ")));
                currentWords = [];
            }
        }


        this._removeFromGoogleCloudStorage(jobId);

        rimraf(`${Utils.tempPath}/${jobId}.video`, () => { });
        rimraf(`${Utils.tempPath}/${jobId}.wav`, () => { });

        return subtitiles;
    };


}